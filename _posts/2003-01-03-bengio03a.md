---
title: Quick Training of Probabilistic Neural Nets by Importance Sampling
abstract: Our previous work on statistical language modeling introduced the use of
  probabilistic feedforward neural networks to help dealing with the curse of dimensionality.
  Training this model by maximum likelihood however requires for each example to perform
  as many network passes as there are words in the vocabulary. Inspired by the contrastive
  divergence model, we propose and evaluate sampling-based methods which require network
  passes only for the observed "positive example" and a few sampled negative example
  words. A very significant speed-up is obtained with an adaptive importance sampling.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: bengio03a
month: 0
tex_title: Quick Training of Probabilistic Neural Nets by Importance Sampling
firstpage: 17
lastpage: 24
page: 17-24
order: 17
cycles: false
bibtex_editor: Bishop, Christopher M. and Frey, Brendan J.
editor:
- given: Christopher M.
  family: Bishop
- given: Brendan J.
  family: Frey
bibtex_author: Bengio, Yoshua and Senecal, Jean-S{\'{e}}bastien
author:
- given: Yoshua
  family: Bengio
- given: Jean-SÃ©bastien
  family: Senecal
date: 2003-01-03
note: Reissued by PMLR on 01 April 2021.
address:
container-title: Proceedings of the Ninth International Workshop on Artificial Intelligence
  and Statistics
volume: R4
genre: inproceedings
issued:
  date-parts:
  - 2003
  - 1
  - 3
pdf: http://proceedings.mlr.press/r4/bengio03a/bengio03a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
