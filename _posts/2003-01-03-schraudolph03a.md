---
title: Combining Conjugate Direction Methods with Stochastic Approximation of Gradients
abstract: The method of conjugate directions provides a very effective way to optimize
  large, deterministic systems by gradient descent. In its standard form, however,
  it is not amenable to stochastic approximation of the gradient. Here we explore
  ideas from conjugate gradient in the stochastic (online) setting, using fast Hessian-gradient
  products to set up low-dimensional Krylov subspaces within individual mini-batches.
  In our benchmark experiments the resulting online learning algorithms converge orders
  of magnitude faster than ordinary stochastic gradient descent.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: schraudolph03a
month: 0
tex_title: Combining Conjugate Direction Methods with Stochastic Approximation of
  Gradients
firstpage: 248
lastpage: 253
page: 248-253
order: 248
cycles: false
bibtex_editor: Bishop, Christopher M. and Frey, Brendan J.
editor:
- given: Christopher M.
  family: Bishop
- given: Brendan J.
  family: Frey
bibtex_author: Schraudolph, Nicol N. and Graepel, Thore
author:
- given: Nicol N.
  family: Schraudolph
- given: Thore
  family: Graepel
date: 2003-01-03
note: Reissued by PMLR on 01 April 2021.
address:
container-title: Proceedings of the Ninth International Workshop on Artificial Intelligence
  and Statistics
volume: R4
genre: inproceedings
issued:
  date-parts:
  - 2003
  - 1
  - 3
pdf: http://proceedings.mlr.press/r4/schraudolph03a/schraudolph03a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
